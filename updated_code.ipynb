{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9199d17-8442-480c-9277-11789da0f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Active Learning Pipeline with 10 iterations\n",
      "Initial samples: 512, adding 50 per iteration\n",
      "Warning: Only 512 images available in initial training set (requested 512)\n",
      "Copied 512 initial images to iteration 1 folder\n",
      "\n",
      "================================================================================\n",
      " ITERATION 1/10\n",
      "================================================================================\n",
      "Training on 512 samples for iteration 1\n",
      "\n",
      " Starting training for Iteration 1...\n",
      "Epoch 10/200, Loss: 1.0998\n",
      "Epoch 20/200, Loss: 0.9435\n",
      "Epoch 30/200, Loss: 0.8600\n",
      "Epoch 40/200, Loss: 0.7579\n",
      "Epoch 50/200, Loss: 0.7048\n",
      "Epoch 60/200, Loss: 0.6063\n",
      "Epoch 70/200, Loss: 0.5279\n",
      "Epoch 80/200, Loss: 0.4534\n",
      "Epoch 90/200, Loss: 0.3753\n",
      "Epoch 100/200, Loss: 0.3238\n",
      "Epoch 110/200, Loss: 0.2776\n",
      "Epoch 120/200, Loss: 0.2165\n",
      "Epoch 130/200, Loss: 0.2048\n",
      "Epoch 140/200, Loss: 0.1713\n",
      "Epoch 150/200, Loss: 0.1480\n",
      "Epoch 160/200, Loss: 0.1343\n",
      "Epoch 170/200, Loss: 0.1597\n",
      "Epoch 180/200, Loss: 0.1013\n",
      "Epoch 190/200, Loss: 0.1031\n",
      "Epoch 200/200, Loss: 0.1922\n",
      "Training completed in 3010.29 seconds\n",
      " Training details saved to ./active_learning_results2\\iteration1\\iteration1_training_details.xlsx\n",
      "\n",
      " Running predictions and uncertainty analysis for Iteration 1...\n",
      " Validation report saved to ./active_learning_results2\\iteration1\\results\\iteration1_validation_report.xlsx\n",
      "\n",
      " Selecting top 50 most uncertain samples for next iteration...\n",
      " Selected 50 samples added to next iteration's training set\n",
      "Next iteration will use 562 total training samples\n",
      "\n",
      "================================================================================\n",
      " ITERATION 2/10\n",
      "================================================================================\n",
      "Training on 562 samples for iteration 2\n",
      "\n",
      " Starting training for Iteration 2...\n",
      "Epoch 10/200, Loss: 1.1806\n",
      "Epoch 20/200, Loss: 1.0991\n",
      "Epoch 30/200, Loss: 0.9262\n",
      "Epoch 40/200, Loss: 0.9071\n",
      "Epoch 50/200, Loss: 0.8604\n",
      "Epoch 60/200, Loss: 0.7713\n",
      "Epoch 70/200, Loss: 0.6740\n",
      "Epoch 80/200, Loss: 0.6603\n",
      "Epoch 90/200, Loss: 0.6095\n",
      "Epoch 100/200, Loss: 0.4815\n",
      "Epoch 110/200, Loss: 0.5134\n",
      "Epoch 120/200, Loss: 0.3878\n",
      "Epoch 130/200, Loss: 0.3544\n",
      "Epoch 140/200, Loss: 0.3009\n",
      "Epoch 150/200, Loss: 0.2699\n",
      "Epoch 160/200, Loss: 0.2836\n",
      "Epoch 170/200, Loss: 0.2533\n",
      "Epoch 180/200, Loss: 0.2695\n",
      "Epoch 190/200, Loss: 0.2316\n",
      "Epoch 200/200, Loss: 0.1939\n",
      "Training completed in 3421.76 seconds\n",
      " Training details saved to ./active_learning_results2\\iteration2\\iteration2_training_details.xlsx\n",
      "\n",
      " Running predictions and uncertainty analysis for Iteration 2...\n",
      " Validation report saved to ./active_learning_results2\\iteration2\\results\\iteration2_validation_report.xlsx\n",
      "\n",
      " Selecting top 50 most uncertain samples for next iteration...\n",
      " Selected 50 samples added to next iteration's training set\n",
      "Next iteration will use 612 total training samples\n",
      "\n",
      "================================================================================\n",
      " ITERATION 3/10\n",
      "================================================================================\n",
      "Training on 612 samples for iteration 3\n",
      "\n",
      " Starting training for Iteration 3...\n",
      "Epoch 10/200, Loss: 1.2344\n",
      "Epoch 20/200, Loss: 1.0614\n",
      "Epoch 30/200, Loss: 0.9787\n",
      "Epoch 40/200, Loss: 0.8819\n",
      "Epoch 50/200, Loss: 0.8068\n",
      "Epoch 60/200, Loss: 0.7490\n",
      "Epoch 70/200, Loss: 0.6564\n",
      "Epoch 80/200, Loss: 0.5936\n",
      "Epoch 90/200, Loss: 0.5404\n",
      "Epoch 100/200, Loss: 0.5501\n",
      "Epoch 110/200, Loss: 0.4019\n",
      "Epoch 120/200, Loss: 0.3343\n"
     ]
    }
   ],
   "source": [
    "# Enhancements to Active Learning Pipeline\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Class Names\n",
    "class_names = [\n",
    "    \"Background\", \"Bareland\", \"Rangeland\", \"Developed Space\", \"Road\",\n",
    "    \"Tree\", \"Water\", \"Agriculture Land\", \"Building\"\n",
    "]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# UNet Model Definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(3, 64)\n",
    "        self.contracting_12 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_21 = self.conv_block(64, 128)\n",
    "        self.contracting_22 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_31 = self.conv_block(128, 256)\n",
    "        self.contracting_32 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_41 = self.conv_block(256, 512)\n",
    "        self.contracting_42 = nn.MaxPool2d(2, 2)\n",
    "        self.middle = self.conv_block(512, 1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(1024, 512, 3, 2, 1, 1)\n",
    "        self.expansive_12 = self.conv_block(1024, 512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(512, 256, 3, 2, 1, 1)\n",
    "        self.expansive_22 = self.conv_block(512, 256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "        self.expansive_32 = self.conv_block(256, 128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n",
    "        self.expansive_42 = self.conv_block(128, 64)\n",
    "        self.output = nn.Conv2d(64, num_classes, 3, 1, 1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c1 = self.contracting_11(x)\n",
    "        p1 = self.contracting_12(c1)\n",
    "        c2 = self.contracting_21(p1)\n",
    "        p2 = self.contracting_22(c2)\n",
    "        c3 = self.contracting_31(p2)\n",
    "        p3 = self.contracting_32(c3)\n",
    "        c4 = self.contracting_41(p3)\n",
    "        p4 = self.contracting_42(c4)\n",
    "        middle = self.middle(p4)\n",
    "        u1 = self.expansive_11(middle)\n",
    "        u1 = self.expansive_12(torch.cat((u1, c4), dim=1))\n",
    "        u2 = self.expansive_21(u1)\n",
    "        u2 = self.expansive_22(torch.cat((u2, c3), dim=1))\n",
    "        u3 = self.expansive_31(u2)\n",
    "        u3 = self.expansive_32(torch.cat((u3, c2), dim=1))\n",
    "        u4 = self.expansive_41(u3)\n",
    "        u4 = self.expansive_42(torch.cat((u4, c1), dim=1))\n",
    "        output = self.output(u4)\n",
    "        return output\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.mask_paths = sorted([os.path.join(mask_dir, img) for img in os.listdir(mask_dir) if img.endswith(('.jpg', '.png', '.tif'))])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with error checking\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "        \n",
    "        # Load images\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Failed to load mask: {mask_path}\")\n",
    "        \n",
    "        # Check image dimensions\n",
    "        if image.size == 0:\n",
    "            raise ValueError(f\"Empty image: {image_path}, shape: {image.shape}\")\n",
    "        \n",
    "        if mask.size == 0:\n",
    "            raise ValueError(f\"Empty mask: {mask_path}, shape: {mask.shape}\")\n",
    "        \n",
    "        # Resize with proper error handling\n",
    "        try:\n",
    "            image = cv2.resize(image, (512, 512))\n",
    "            mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "        except cv2.error as e:\n",
    "            print(f\"Resize error on image {image_path}, shape: {image.shape}\")\n",
    "            print(f\"Resize error on mask {mask_path}, shape: {mask.shape}\")\n",
    "            raise e\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        mask = torch.clamp(mask, 0, 8)  # Ensure mask values are within valid range\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Similarly update ValidationDataset.__getitem__ with error handling\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir=None):\n",
    "        self.image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.has_labels = label_dir is not None\n",
    "        \n",
    "        if self.has_labels:\n",
    "            self.label_paths = sorted([os.path.join(label_dir, img) for img in os.listdir(label_dir) if img.endswith(('.jpg', '.png', '.tif'))])\n",
    "        else:\n",
    "            self.label_paths = [None] * len(self.image_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            \n",
    "        # Check image dimensions\n",
    "        if image.size == 0:\n",
    "            raise ValueError(f\"Empty image: {image_path}, shape: {image.shape}\")\n",
    "        \n",
    "        # Resize with proper error handling\n",
    "        try:\n",
    "            image = cv2.resize(image, (512, 512))\n",
    "        except cv2.error as e:\n",
    "            print(f\"Resize error on image {image_path}, shape: {image.shape}\")\n",
    "            raise e\n",
    "            \n",
    "        image_tensor = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        if self.has_labels and self.label_paths[idx]:\n",
    "            label_path = self.label_paths[idx]\n",
    "            \n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Warning: Label file not found: {label_path}, using zeros\")\n",
    "                label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "            else:\n",
    "                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if label is None:\n",
    "                    print(f\"Warning: Failed to load label: {label_path}, using zeros\")\n",
    "                    label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "                else:\n",
    "                    try:\n",
    "                        label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "                        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "                    except cv2.error as e:\n",
    "                        print(f\"Resize error on label {label_path}, shape: {label.shape}\")\n",
    "                        label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "        else:\n",
    "            label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, label_tensor, self.image_paths[idx]\n",
    "\n",
    "\n",
    "def validate_dataset_files(dataset_dir, type_str=\"images\"):\n",
    "    print(f\"Validating {type_str} in {dataset_dir}...\")\n",
    "    invalid_files = []\n",
    "\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(('.jpg', '.png', '.tif')):\n",
    "            file_path = os.path.join(dataset_dir, file)\n",
    "\n",
    "            try:\n",
    "                if type_str in [\"masks\", \"labels\"]:\n",
    "                    img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "                else:\n",
    "                    img = cv2.imread(file_path)\n",
    "\n",
    "                if img is None or img.size == 0:\n",
    "                    print(f\"Issue with {file_path}, shape: {getattr(img, 'shape', 'N/A')}\")\n",
    "                    invalid_files.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                # Try resizing\n",
    "                resize_mode = cv2.INTER_NEAREST if type_str in [\"masks\", \"labels\"] else cv2.INTER_LINEAR\n",
    "                cv2.resize(img, (512, 512), interpolation=resize_mode)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {file_path}: {str(e)}\")\n",
    "                invalid_files.append(file_path)\n",
    "\n",
    "    if invalid_files:\n",
    "        print(f\"Found {len(invalid_files)} invalid {type_str} files\")\n",
    "    else:\n",
    "        print(f\"All {type_str} files validated successfully\")\n",
    "\n",
    "    return invalid_files\n",
    "\n",
    "    for _, mask in dataset:\n",
    "        unique, counts = np.unique(mask.numpy(), return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            if u < len(class_counts):  # Ensure valid class index\n",
    "                class_counts[u] += c\n",
    "        total_pixels += mask.numel()\n",
    "    \n",
    "    class_percentage = (class_counts / total_pixels) * 100\n",
    "    return class_counts, class_percentage\n",
    "\n",
    "def compute_class_distribution(dataset):\n",
    "    class_counts = np.zeros(len(class_names))\n",
    "    total_pixels = 0\n",
    "\n",
    "    for _, mask in dataset:\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.numpy()\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            if u < len(class_counts):  # Make sure it's a valid class index\n",
    "                class_counts[u] += c\n",
    "        total_pixels += mask.size\n",
    "\n",
    "    class_percentage = (class_counts / total_pixels) * 100\n",
    "    return class_counts, class_percentage\n",
    "def compute_entropy(prob_map):\n",
    "    \"\"\"Compute pixel-wise entropy as uncertainty measure\"\"\"\n",
    "    entropy = -torch.sum(prob_map * torch.log(prob_map + 1e-10), dim=0)\n",
    "    return entropy\n",
    "\n",
    "def compute_miou(preds, targets):\n",
    "    \"\"\"Compute mean IoU and class-wise IoU\"\"\"\n",
    "    iou_per_class = np.zeros(num_classes)\n",
    "    preds = preds.flatten()\n",
    "    targets = targets.flatten()\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        if (targets == cls).sum() == 0:\n",
    "            iou_per_class[cls] = np.nan\n",
    "            continue\n",
    "        iou_per_class[cls] = jaccard_score(targets == cls, preds == cls)\n",
    "    \n",
    "    return np.nanmean(iou_per_class), iou_per_class\n",
    "\n",
    "def plot_training_loss(loss_history, iteration, save_dir):\n",
    "    \"\"\"Plot and save training loss graph\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history)\n",
    "    plt.title(f'Training Loss - Iteration {iteration}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_training_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "def create_directories(base_dir, iteration):\n",
    "    \"\"\"Create all necessary directories for the current iteration\"\"\"\n",
    "    dirs = {\n",
    "        'iteration_dir': os.path.join(base_dir, f'iteration{iteration}'),\n",
    "        'train_data': os.path.join(base_dir, f'iteration{iteration}', 'train_data'),\n",
    "        'train_labels': os.path.join(base_dir, f'iteration{iteration}', 'train_labels'),\n",
    "        'results': os.path.join(base_dir, f'iteration{iteration}', 'results'),\n",
    "        'predicted_masks': os.path.join(base_dir, f'iteration{iteration}', 'results', 'predicted_masks'),\n",
    "        'high_uncertainty': os.path.join(base_dir, f'iteration{iteration}', 'results', 'uncertainty_high'),\n",
    "        'low_uncertainty': os.path.join(base_dir, f'iteration{iteration}', 'results', 'uncertainty_low'),\n",
    "        'heatmaps': os.path.join(base_dir, f'iteration{iteration}', 'results', 'heatmaps'),\n",
    "    }\n",
    "    \n",
    "    for dir_path in dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "# Training Function\n",
    "def train_model(train_loader, model, criterion, optimizer, num_epochs, device, iteration, save_dir):\n",
    "    \"\"\"Train the model and save results\"\"\"\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_loss = float('inf')\n",
    "    loss_history = []\n",
    "    \n",
    "    print(f\"\\n Starting training for Iteration {iteration}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        loss_history.append(avg_epoch_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            model_path = os.path.join(save_dir, f'iteration{iteration}_model.pth')\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Plot training loss\n",
    "    plot_training_loss(loss_history, iteration, save_dir)\n",
    "    \n",
    "    # Save training details to Excel\n",
    "    train_details = pd.DataFrame({\n",
    "        \"Metric\": [\"Best Training Loss\", \"Total Training Time (s)\", \"Train Image Count\"],\n",
    "        \"Value\": [best_loss, total_time, len(train_loader.dataset)]\n",
    "    })\n",
    "    \n",
    "    # Compute class distribution\n",
    "    class_counts, class_percentage = compute_class_distribution(train_loader.dataset)\n",
    "    class_distribution_df = pd.DataFrame({\n",
    "        \"Class\": class_names,\n",
    "        \"Pixel Count\": class_counts,\n",
    "        \"Percentage\": class_percentage\n",
    "    })\n",
    "    \n",
    "    # Save to Excel\n",
    "    excel_path = os.path.join(save_dir, f'iteration{iteration}_training_details.xlsx')\n",
    "    with pd.ExcelWriter(excel_path) as writer:\n",
    "        train_details.to_excel(writer, sheet_name=\"Training Details\", index=False)\n",
    "        class_distribution_df.to_excel(writer, sheet_name=\"Class Distribution\", index=False)\n",
    "    \n",
    "    print(f\" Training details saved to {excel_path}\")\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "# Prediction and Uncertainty Estimation\n",
    "def predict_and_analyze(model_path, val_loader, iteration, dirs, device, uncertainty_threshold=0.5):\n",
    "    \"\"\"Make predictions, analyze uncertainty, and select most uncertain samples\"\"\"\n",
    "    print(f\"\\n Running predictions and uncertainty analysis for Iteration {iteration}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(num_classes=num_classes).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Handle both DataParallel and non-DataParallel models\n",
    "    if all(k.startswith('module.') for k in checkpoint.keys()):\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint.items()}\n",
    "    else:\n",
    "        new_state_dict = checkpoint\n",
    "    \n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize metrics\n",
    "    overall_iou_per_class = np.zeros(num_classes)\n",
    "    total_images = 0\n",
    "    total_miou = 0\n",
    "    classwise_pred_counts = np.zeros(num_classes)\n",
    "    classwise_actual_counts = np.zeros(num_classes)\n",
    "    \n",
    "    # Store uncertainty for all images\n",
    "    uncertainty_scores = []\n",
    "    \n",
    "    for img, lbl, img_path in val_loader:\n",
    "        img = img.to(device)\n",
    "        filename = os.path.basename(img_path[0])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            probs = F.softmax(output, dim=1).cpu()\n",
    "            pred_mask = torch.argmax(probs, dim=1)[0].numpy()\n",
    "            entropy_map = compute_entropy(probs[0])\n",
    "        \n",
    "        lbl = lbl.cpu().numpy()[0]\n",
    "        \n",
    "        # Update class-wise pixel counts\n",
    "        for cls in range(num_classes):\n",
    "            classwise_pred_counts[cls] += (pred_mask == cls).sum()\n",
    "            classwise_actual_counts[cls] += (lbl == cls).sum()\n",
    "        \n",
    "        # Compute IoU if we have ground truth\n",
    "        if np.sum(lbl) > 0:\n",
    "            miou, classwise_iou = compute_miou(pred_mask, lbl)\n",
    "            overall_iou_per_class += np.nan_to_num(classwise_iou)\n",
    "            total_miou += miou\n",
    "            total_images += 1\n",
    "        \n",
    "        # Save predicted mask\n",
    "        cv2.imwrite(os.path.join(dirs['predicted_masks'], filename), (pred_mask * 30).astype(np.uint8))\n",
    "        \n",
    "        # Calculate mean uncertainty\n",
    "        mean_uncertainty = entropy_map.mean().item()\n",
    "        uncertainty_scores.append((filename, img_path[0], mean_uncertainty))\n",
    "        \n",
    "        # Create and save uncertainty heatmap\n",
    "        entropy_min = entropy_map.min()\n",
    "        entropy_max = entropy_map.max()\n",
    "        if entropy_max == entropy_min:\n",
    "            entropy_norm = torch.zeros_like(entropy_map)\n",
    "        else:\n",
    "            entropy_norm = ((entropy_map - entropy_min) / (entropy_max - entropy_min)) * 255\n",
    "        \n",
    "        entropy_vis = cv2.applyColorMap(entropy_norm.to(torch.uint8).cpu().numpy(), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Add uncertainty text to heatmap\n",
    "        text = f\"Mean Uncertainty: {mean_uncertainty:.4f}\"\n",
    "        cv2.putText(entropy_vis, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Save heatmap\n",
    "        cv2.imwrite(os.path.join(dirs['heatmaps'], filename), entropy_vis)\n",
    "        \n",
    "        # Save in appropriate uncertainty folder\n",
    "        uncertainty_folder = dirs['high_uncertainty'] if mean_uncertainty > uncertainty_threshold else dirs['low_uncertainty']\n",
    "        cv2.imwrite(os.path.join(uncertainty_folder, filename), (pred_mask * 30).astype(np.uint8))\n",
    "    \n",
    "    # Compute final metrics\n",
    "    avg_miou = total_miou / max(1, total_images)\n",
    "    if total_images > 0:\n",
    "        overall_iou_per_class /= total_images\n",
    "    \n",
    "    # Save validation report\n",
    "    data = [[class_names[cls], overall_iou_per_class[cls], classwise_actual_counts[cls], classwise_pred_counts[cls]] \n",
    "            for cls in range(num_classes)]\n",
    "    data.append([\"Overall mIoU\", avg_miou, \"\", \"\"])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"Class\", \"IoU Score\", \"Actual Pixels\", \"Predicted Pixels\"])\n",
    "    report_path = os.path.join(dirs['results'], f'iteration{iteration}_validation_report.xlsx')\n",
    "    df.to_excel(report_path, index=False)\n",
    "    \n",
    "    print(f\" Validation report saved to {report_path}\")\n",
    "    \n",
    "    # Sort by uncertainty and return top uncertain images\n",
    "    uncertainty_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return uncertainty_scores\n",
    "\n",
    "# Select and copy most uncertain samples\n",
    "def select_uncertain_samples(uncertainty_scores, top_n, unlabeled_dir, validation_labels_dir, next_iteration_dirs):\n",
    "    \"\"\"Select top N uncertain samples and move them to the next iteration's training folders\"\"\"\n",
    "    print(f\"\\n Selecting top {top_n} most uncertain samples for next iteration...\")\n",
    "    \n",
    "    # Get top N uncertain images\n",
    "    top_uncertain = uncertainty_scores[:top_n]\n",
    "    \n",
    "    # Create CSV with uncertainty data\n",
    "    uncertainty_df = pd.DataFrame(uncertainty_scores, columns=[\"Filename\", \"Path\", \"Uncertainty\"])\n",
    "    uncertainty_df.to_csv(os.path.join(os.path.dirname(next_iteration_dirs['train_data']), \"uncertainty_scores.csv\"), index=False)\n",
    "    \n",
    "    # Copy images and labels to next iteration's training folders\n",
    "    for _, img_path, uncertainty in top_uncertain:\n",
    "        filename = os.path.basename(img_path)\n",
    "        \n",
    "        # Copy image to next iteration's training data\n",
    "        shutil.copy2(img_path, os.path.join(next_iteration_dirs['train_data'], filename))\n",
    "        \n",
    "        # Copy corresponding label if available\n",
    "        label_path = os.path.join(validation_labels_dir, filename)\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy2(label_path, os.path.join(next_iteration_dirs['train_labels'], filename))\n",
    "    \n",
    "    print(f\" Selected {top_n} samples added to next iteration's training set\")\n",
    "    return top_uncertain\n",
    "\n",
    "# Mai\n",
    "\n",
    "def active_learning_pipeline(base_dir, initial_train_data, initial_train_labels, \n",
    "                            unlabeled_data, validation_labels, \n",
    "                            total_iterations=10, initial_samples=512, samples_per_iteration=50,\n",
    "                            uncertainty_threshold=0.5, num_epochs=200, batch_size=16):\n",
    "    \"\"\"Run the complete active learning pipeline for semantic segmentation\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Starting Active Learning Pipeline with {total_iterations} iterations\")\n",
    "    print(f\"Initial samples: {initial_samples}, adding {samples_per_iteration} per iteration\")\n",
    "    \n",
    "    # Prepare CSV file to track metrics across iterations\n",
    "    metrics_tracking = []\n",
    "    metrics_file = os.path.join(base_dir, \"active_learning_metrics.xlsx\")\n",
    "    \n",
    "    # Setup initial directories\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    # Prepare a list of all images in the initial training folder\n",
    "    all_train_images = sorted([f for f in os.listdir(initial_train_data) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "    \n",
    "    # Select initial_samples\n",
    "    if len(all_train_images) > initial_samples:\n",
    "        # Randomly select initial_samples images\n",
    "        import random\n",
    "        random.seed(42)  # For reproducibility\n",
    "        selected_images = random.sample(all_train_images, initial_samples)\n",
    "    else:\n",
    "        selected_images = all_train_images\n",
    "        print(f\"Warning: Only {len(selected_images)} images available in initial training set (requested {initial_samples})\")\n",
    "    \n",
    "    # For the first iteration, create folders and copy selected images\n",
    "    iteration1_dirs = create_directories(base_dir, 1)\n",
    "    \n",
    "    # Copy selected initial samples to iteration 1 folder\n",
    "    for img_file in selected_images:\n",
    "        # Copy image\n",
    "        src_img = os.path.join(initial_train_data, img_file)\n",
    "        dst_img = os.path.join(iteration1_dirs['train_data'], img_file)\n",
    "        shutil.copy2(src_img, dst_img)\n",
    "        \n",
    "        # Copy corresponding label\n",
    "        src_label = os.path.join(initial_train_labels, img_file)\n",
    "        dst_label = os.path.join(iteration1_dirs['train_labels'], img_file)\n",
    "        if os.path.exists(src_label):\n",
    "            shutil.copy2(src_label, dst_label)\n",
    "    \n",
    "    print(f\"Copied {len(selected_images)} initial images to iteration 1 folder\")\n",
    "    \n",
    "    # Now run all iterations\n",
    "    for iteration in range(1, total_iterations + 1):\n",
    "        print(f\"\\n{'='*80}\\n ITERATION {iteration}/{total_iterations}\\n{'='*80}\")\n",
    "        \n",
    "        # Create directories for this iteration (or use existing ones for iteration 1)\n",
    "        if iteration == 1:\n",
    "            dirs = iteration1_dirs\n",
    "        else:\n",
    "            dirs = create_directories(base_dir, iteration)\n",
    "        \n",
    "        # Count how many training samples we have for this iteration\n",
    "        train_sample_count = len(os.listdir(dirs['train_data']))\n",
    "        print(f\"Training on {train_sample_count} samples for iteration {iteration}\")\n",
    "        \n",
    "        # 1. Train model\n",
    "        train_dataset = SegmentationDataset(dirs['train_data'], dirs['train_labels'])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        \n",
    "        # Compute class distribution BEFORE training\n",
    "        train_class_counts, train_class_percentage = compute_class_distribution(train_dataset)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = UNet(num_classes=num_classes)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "        \n",
    "        training_start_time = time.time()\n",
    "        model_path, loss_history = train_model_enhanced(\n",
    "            train_loader=train_loader,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            num_epochs=num_epochs,\n",
    "            device=device,\n",
    "            iteration=iteration,\n",
    "            save_dir=dirs['iteration_dir']\n",
    "        )\n",
    "        training_time = time.time() - training_start_time\n",
    "        \n",
    "        # 2. Make predictions, analyze uncertainty and validate\n",
    "        val_dataset = ValidationDataset(unlabeled_data, validation_labels)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # Run validation with enhanced metrics\n",
    "        uncertainty_scores, val_metrics = predict_and_analyze_enhanced(\n",
    "            model_path=model_path,\n",
    "            val_loader=val_loader,\n",
    "            iteration=iteration,\n",
    "            dirs=dirs,\n",
    "            device=device,\n",
    "            uncertainty_threshold=uncertainty_threshold\n",
    "        )\n",
    "        \n",
    "        # Track metrics for this iteration\n",
    "        iteration_metrics = {\n",
    "            \"Iteration\": iteration,\n",
    "            \"Training Samples\": train_sample_count,\n",
    "            \"Training Time (s)\": training_time,\n",
    "            \"Final Training Loss\": loss_history[-1] if loss_history else float('nan'),\n",
    "            \"Best Training Loss\": min(loss_history) if loss_history else float('nan'),\n",
    "            \"Validation mIoU\": val_metrics['miou'],\n",
    "            \"High Uncertainty Count\": val_metrics['high_uncertainty_count'],\n",
    "            \"Low Uncertainty Count\": val_metrics['low_uncertainty_count'],\n",
    "            \"Average Uncertainty\": val_metrics['avg_uncertainty']\n",
    "        }\n",
    "        \n",
    "        # Add class-specific IoUs\n",
    "        for i, cls_name in enumerate(class_names):\n",
    "            iteration_metrics[f\"IoU_{cls_name}\"] = val_metrics['class_iou'][i]\n",
    "        \n",
    "        metrics_tracking.append(iteration_metrics)\n",
    "        \n",
    "        # Save accumulated metrics to excel\n",
    "        metrics_df = pd.DataFrame(metrics_tracking)\n",
    "        metrics_df.to_excel(metrics_file, index=False)\n",
    "        \n",
    "        # 3. If not the last iteration, select samples for next iteration\n",
    "        if iteration < total_iterations:\n",
    "            next_iteration_dirs = create_directories(base_dir, iteration + 1)\n",
    "            \n",
    "            # First copy ALL current iteration data to next iteration folders\n",
    "            for file in os.listdir(dirs['train_data']):\n",
    "                shutil.copy2(os.path.join(dirs['train_data'], file), \n",
    "                           os.path.join(next_iteration_dirs['train_data'], file))\n",
    "                \n",
    "            for file in os.listdir(dirs['train_labels']):\n",
    "                shutil.copy2(os.path.join(dirs['train_labels'], file), \n",
    "                           os.path.join(next_iteration_dirs['train_labels'], file))\n",
    "            \n",
    "            # Then select and add the new samples\n",
    "            new_samples = select_uncertain_samples(\n",
    "                uncertainty_scores=uncertainty_scores,\n",
    "                top_n=samples_per_iteration,\n",
    "                unlabeled_dir=unlabeled_data,\n",
    "                validation_labels_dir=validation_labels,\n",
    "                next_iteration_dirs=next_iteration_dirs\n",
    "            )\n",
    "            \n",
    "            # Track the newly added samples\n",
    "            new_samples_df = pd.DataFrame(new_samples, columns=[\"Filename\", \"Path\", \"Uncertainty\"])\n",
    "            new_samples_df.to_csv(os.path.join(next_iteration_dirs['iteration_dir'], f\"new_samples_iter{iteration+1}.csv\"), index=False)\n",
    "            \n",
    "            print(f\"Next iteration will use {len(os.listdir(next_iteration_dirs['train_data']))} total training samples\")\n",
    "    \n",
    "    # Create summary plots after all iterations\n",
    "    create_summary_plots(base_dir, metrics_tracking)\n",
    "    \n",
    "    print(f\"\\n Active Learning Pipeline Completed Successfully!\")\n",
    "    print(f\"Results saved in: {base_dir}\")\n",
    "    print(f\"Summary metrics saved to: {metrics_file}\")\n",
    "\n",
    "\n",
    "def train_model_enhanced(train_loader, model, criterion, optimizer, num_epochs, device, iteration, save_dir):\n",
    "    \"\"\"Train the model and save results with enhanced metrics\"\"\"\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_loss = float('inf')\n",
    "    loss_history = []\n",
    "    validation_loss_history = []  # For validation loss if available\n",
    "    \n",
    "    print(f\"\\n Starting training for Iteration {iteration}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        loss_history.append(avg_epoch_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            model_path = os.path.join(save_dir, f'iteration{iteration}_model.pth')\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Plot training loss\n",
    "    plot_training_loss(loss_history, iteration, save_dir)\n",
    "    \n",
    "    # Save training details to Excel\n",
    "    train_details = pd.DataFrame({\n",
    "        \"Metric\": [\"Best Training Loss\", \"Total Training Time (s)\", \"Train Image Count\", \"Final Loss\"],\n",
    "        \"Value\": [best_loss, total_time, len(train_loader.dataset), loss_history[-1]]\n",
    "    })\n",
    "    \n",
    "    # Compute class distribution\n",
    "    class_counts, class_percentage = compute_class_distribution(train_loader.dataset)\n",
    "    class_distribution_df = pd.DataFrame({\n",
    "        \"Class\": class_names,\n",
    "        \"Pixel Count\": class_counts,\n",
    "        \"Percentage\": class_percentage\n",
    "    })\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plot_class_distribution(class_names, class_percentage, iteration, save_dir)\n",
    "    \n",
    "    # Save epoch-wise loss to CSV\n",
    "    epoch_loss_df = pd.DataFrame({\n",
    "        \"Epoch\": list(range(1, num_epochs + 1)),\n",
    "        \"Loss\": loss_history\n",
    "    })\n",
    "    epoch_loss_df.to_csv(os.path.join(save_dir, f'iteration{iteration}_epoch_loss.csv'), index=False)\n",
    "    \n",
    "    # Save to Excel\n",
    "    excel_path = os.path.join(save_dir, f'iteration{iteration}_training_details.xlsx')\n",
    "    with pd.ExcelWriter(excel_path) as writer:\n",
    "        train_details.to_excel(writer, sheet_name=\"Training Details\", index=False)\n",
    "        class_distribution_df.to_excel(writer, sheet_name=\"Class Distribution\", index=False)\n",
    "        epoch_loss_df.to_excel(writer, sheet_name=\"Epoch Loss\", index=False)\n",
    "    \n",
    "    print(f\" Training details saved to {excel_path}\")\n",
    "    \n",
    "    return model_path, loss_history\n",
    "\n",
    "\n",
    "def predict_and_analyze_enhanced(model_path, val_loader, iteration, dirs, device, uncertainty_threshold=0.5):\n",
    "    \"\"\"Make predictions, analyze uncertainty, and select most uncertain samples with enhanced metrics\"\"\"\n",
    "    print(f\"\\n Running predictions and uncertainty analysis for Iteration {iteration}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = UNet(num_classes=num_classes).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Handle both DataParallel and non-DataParallel models\n",
    "    if all(k.startswith('module.') for k in checkpoint.keys()):\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint.items()}\n",
    "    else:\n",
    "        new_state_dict = checkpoint\n",
    "    \n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize metrics\n",
    "    overall_iou_per_class = np.zeros(num_classes)\n",
    "    total_images = 0\n",
    "    total_miou = 0\n",
    "    classwise_pred_counts = np.zeros(num_classes)\n",
    "    classwise_actual_counts = np.zeros(num_classes)\n",
    "    \n",
    "    # Store uncertainty for all images\n",
    "    uncertainty_scores = []\n",
    "    all_uncertainties = []\n",
    "    high_uncertainty_count = 0\n",
    "    low_uncertainty_count = 0\n",
    "    \n",
    "    # Confusion matrix for class prediction\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    \n",
    "    for img, lbl, img_path in val_loader:\n",
    "        img = img.to(device)\n",
    "        filename = os.path.basename(img_path[0])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            probs = F.softmax(output, dim=1).cpu()\n",
    "            pred_mask = torch.argmax(probs, dim=1)[0].numpy()\n",
    "            entropy_map = compute_entropy(probs[0])\n",
    "        \n",
    "        lbl = lbl.cpu().numpy()[0]\n",
    "        \n",
    "        # Update class-wise pixel counts\n",
    "        for cls in range(num_classes):\n",
    "            classwise_pred_counts[cls] += (pred_mask == cls).sum()\n",
    "            classwise_actual_counts[cls] += (lbl == cls).sum()\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        for true_cls in range(num_classes):\n",
    "            for pred_cls in range(num_classes):\n",
    "                confusion_matrix[true_cls, pred_cls] += np.sum((lbl == true_cls) & (pred_mask == pred_cls))\n",
    "        \n",
    "        # Compute IoU if we have ground truth\n",
    "        if np.sum(lbl) > 0:\n",
    "            miou, classwise_iou = compute_miou(pred_mask, lbl)\n",
    "            overall_iou_per_class += np.nan_to_num(classwise_iou)\n",
    "            total_miou += miou\n",
    "            total_images += 1\n",
    "        \n",
    "        # Save predicted mask\n",
    "        cv2.imwrite(os.path.join(dirs['predicted_masks'], filename), (pred_mask * 30).astype(np.uint8))\n",
    "        \n",
    "        # Calculate mean uncertainty\n",
    "        mean_uncertainty = entropy_map.mean().item()\n",
    "        all_uncertainties.append(mean_uncertainty)\n",
    "        uncertainty_scores.append((filename, img_path[0], mean_uncertainty))\n",
    "        \n",
    "        # Create and save uncertainty heatmap\n",
    "        entropy_min = entropy_map.min()\n",
    "        entropy_max = entropy_map.max()\n",
    "        if entropy_max == entropy_min:\n",
    "            entropy_norm = torch.zeros_like(entropy_map)\n",
    "        else:\n",
    "            entropy_norm = ((entropy_map - entropy_min) / (entropy_max - entropy_min)) * 255\n",
    "        \n",
    "        entropy_vis = cv2.applyColorMap(entropy_norm.to(torch.uint8).cpu().numpy(), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Add uncertainty text to heatmap\n",
    "        text = f\"Mean Uncertainty: {mean_uncertainty:.4f}\"\n",
    "        cv2.putText(entropy_vis, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Save heatmap\n",
    "        cv2.imwrite(os.path.join(dirs['heatmaps'], filename), entropy_vis)\n",
    "        \n",
    "        # Save in appropriate uncertainty folder\n",
    "        if mean_uncertainty > uncertainty_threshold:\n",
    "            uncertainty_folder = dirs['high_uncertainty']\n",
    "            high_uncertainty_count += 1\n",
    "        else:\n",
    "            uncertainty_folder = dirs['low_uncertainty']\n",
    "            low_uncertainty_count += 1\n",
    "            \n",
    "        cv2.imwrite(os.path.join(uncertainty_folder, filename), (pred_mask * 30).astype(np.uint8))\n",
    "    \n",
    "    # Compute final metrics\n",
    "    avg_miou = total_miou / max(1, total_images)\n",
    "    if total_images > 0:\n",
    "        overall_iou_per_class /= total_images\n",
    "    \n",
    "    # Save validation report\n",
    "    data = [[class_names[cls], overall_iou_per_class[cls], classwise_actual_counts[cls], classwise_pred_counts[cls]] \n",
    "            for cls in range(num_classes)]\n",
    "    data.append([\"Overall mIoU\", avg_miou, \"\", \"\"])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"Class\", \"IoU Score\", \"Actual Pixels\", \"Predicted Pixels\"])\n",
    "    report_path = os.path.join(dirs['results'], f'iteration{iteration}_validation_report.xlsx')\n",
    "    df.to_excel(report_path, index=False)\n",
    "    \n",
    "    # Save confusion matrix\n",
    "    confusion_df = pd.DataFrame(confusion_matrix, \n",
    "                               index=[f\"True_{cls}\" for cls in class_names],\n",
    "                               columns=[f\"Pred_{cls}\" for cls in class_names])\n",
    "    confusion_df.to_excel(os.path.join(dirs['results'], f'iteration{iteration}_confusion_matrix.xlsx'))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(confusion_matrix, class_names, iteration, dirs['results'])\n",
    "    \n",
    "    # Plot uncertainty distribution\n",
    "    plot_uncertainty_distribution(all_uncertainties, uncertainty_threshold, iteration, dirs['results'])\n",
    "    \n",
    "    # Plot IoU per class\n",
    "    plot_iou_per_class(overall_iou_per_class, class_names, iteration, dirs['results'])\n",
    "    \n",
    "    # Plot class distribution comparison (actual vs. predicted)\n",
    "    plot_class_comparison(classwise_actual_counts, classwise_pred_counts, class_names, iteration, dirs['results'])\n",
    "    \n",
    "    print(f\" Validation report saved to {report_path}\")\n",
    "    \n",
    "    # Sort by uncertainty and return metrics\n",
    "    uncertainty_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    val_metrics = {\n",
    "        'miou': avg_miou,\n",
    "        'class_iou': overall_iou_per_class,\n",
    "        'high_uncertainty_count': high_uncertainty_count,\n",
    "        'low_uncertainty_count': low_uncertainty_count,\n",
    "        'avg_uncertainty': np.mean(all_uncertainties) if all_uncertainties else 0,\n",
    "        'confusion_matrix': confusion_matrix,\n",
    "        'classwise_actual_counts': classwise_actual_counts,\n",
    "        'classwise_pred_counts': classwise_pred_counts\n",
    "    }\n",
    "    \n",
    "    return uncertainty_scores, val_metrics\n",
    "\n",
    "\n",
    "# New visualization functions\n",
    "def plot_class_distribution(class_names, class_percentage, iteration, save_dir):\n",
    "    \"\"\"Plot class distribution as a bar chart\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(class_names, class_percentage)\n",
    "    \n",
    "    # Add percentage values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.title(f'Class Distribution - Iteration {iteration}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_class_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names, iteration, save_dir):\n",
    "    \"\"\"Plot confusion matrix as a heatmap\"\"\"\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Normalize by rows (true classes)\n",
    "    row_sums = confusion_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_conf_matrix = np.zeros_like(confusion_matrix, dtype=float)\n",
    "    np.divide(confusion_matrix, row_sums, out=norm_conf_matrix, where=row_sums!=0)\n",
    "    \n",
    "    plt.imshow(norm_conf_matrix, cmap='Blues')\n",
    "    plt.colorbar(label='Normalized Count')\n",
    "    \n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = norm_conf_matrix.max() / 2.\n",
    "    for i in range(norm_conf_matrix.shape[0]):\n",
    "        for j in range(norm_conf_matrix.shape[1]):\n",
    "            plt.text(j, i, f'{norm_conf_matrix[i, j]:.2f}',\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if norm_conf_matrix[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title(f'Normalized Confusion Matrix - Iteration {iteration}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_uncertainty_distribution(uncertainties, threshold, iteration, save_dir):\n",
    "    \"\"\"Plot histogram of uncertainty values\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(uncertainties, bins=30, alpha=0.7, color='skyblue')\n",
    "    plt.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold ({threshold})')\n",
    "    \n",
    "    # Add counts of high/low uncertainty\n",
    "    high_count = sum(1 for u in uncertainties if u > threshold)\n",
    "    low_count = len(uncertainties) - high_count\n",
    "    \n",
    "    plt.text(threshold*1.05, plt.ylim()[1]*0.9, f'High: {high_count}', color='r')\n",
    "    plt.text(threshold*0.8, plt.ylim()[1]*0.9, f'Low: {low_count}', color='g')\n",
    "    \n",
    "    plt.xlabel('Uncertainty Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Uncertainty Distribution - Iteration {iteration}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_uncertainty_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_iou_per_class(iou_values, class_names, iteration, save_dir):\n",
    "    \"\"\"Plot IoU values per class\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(class_names, iou_values)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.title(f'IoU per Class - Iteration {iteration}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('IoU Score')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_iou_per_class.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_class_comparison(actual_counts, pred_counts, class_names, iteration, save_dir):\n",
    "    \"\"\"Plot comparison between actual and predicted class distributions\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Convert to percentages\n",
    "    total_actual = actual_counts.sum()\n",
    "    total_pred = pred_counts.sum()\n",
    "    actual_pct = actual_counts / total_actual * 100 if total_actual > 0 else np.zeros_like(actual_counts)\n",
    "    pred_pct = pred_counts / total_pred * 100 if total_pred > 0 else np.zeros_like(pred_counts)\n",
    "    \n",
    "    ax.bar(x - width/2, actual_pct, width, label='Ground Truth')\n",
    "    ax.bar(x + width/2, pred_pct, width, label='Predicted')\n",
    "    \n",
    "    ax.set_title(f'Class Distribution Comparison - Iteration {iteration}')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'iteration{iteration}_class_comparison.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_summary_plots(base_dir, metrics_tracking):\n",
    "    \"\"\"Create summary plots for all iterations\"\"\"\n",
    "    metrics_df = pd.DataFrame(metrics_tracking)\n",
    "    \n",
    "    # Directory for summary plots\n",
    "    summary_dir = os.path.join(base_dir, \"summary_plots\")\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Plot training samples progression\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Training Samples\"], marker='o', linewidth=2)\n",
    "    plt.title('Training Sample Count Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Number of Training Samples')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'training_samples_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Plot training loss progression\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Final Training Loss\"], marker='o', label='Final Loss', linewidth=2)\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Best Training Loss\"], marker='s', label='Best Loss', linewidth=2)\n",
    "    plt.title('Training Loss Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'training_loss_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Plot mIoU progression\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Validation mIoU\"], marker='o', linewidth=2)\n",
    "    plt.title('Validation mIoU Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('mIoU')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'miou_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Plot class-wise IoU progression\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for cls in class_names:\n",
    "        if f\"IoU_{cls}\" in metrics_df.columns:\n",
    "            plt.plot(metrics_df[\"Iteration\"], metrics_df[f\"IoU_{cls}\"], marker='o', label=cls)\n",
    "    plt.title('Class-wise IoU Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(summary_dir, 'class_iou_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Plot uncertainty metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Average Uncertainty\"], marker='o', color='purple', linewidth=2)\n",
    "    plt.title('Average Uncertainty Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average Uncertainty')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'uncertainty_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Plot high vs low uncertainty counts\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"High Uncertainty Count\"], marker='o', label='High Uncertainty', linewidth=2)\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Low Uncertainty Count\"], marker='s', label='Low Uncertainty', linewidth=2)\n",
    "    plt.title('Uncertainty Distribution Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'uncertainty_counts_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 7. Plot training time progression\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics_df[\"Iteration\"], metrics_df[\"Training Time (s)\"], marker='o', linewidth=2)\n",
    "    plt.title('Training Time Progression')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(summary_dir, 'training_time_progression.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Summary plots saved to {summary_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory where all iterations will be stored\n",
    "    base_dir = \"./active_learning_results2\"\n",
    "    \n",
    "    # Paths to your data\n",
    "    initial_train_data = r\"C:\\Users\\SRM\\Desktop\\Active Learning Project\\Open Earth Data Set\\dfc25_track1_trainval\\Data\\SegXAL\\data\\train_data\"\n",
    "    initial_train_labels = r\"C:\\Users\\SRM\\Desktop\\Active Learning Project\\Open Earth Data Set\\dfc25_track1_trainval\\Data\\SegXAL\\data\\train_labels\"\n",
    "    unlabeled_data = r\"C:\\Users\\SRM\\Desktop\\Active Learning Project\\Open Earth Data Set\\dfc25_track1_trainval\\Data\\SegXAL\\data\\Unlabeled_data\"  \n",
    "    validation_labels = r\"C:\\Users\\SRM\\Desktop\\Active Learning Project\\Open Earth Data Set\\dfc25_track1_trainval\\Data\\SegXAL\\data\\Validation_labels\"  # Can be None if no ground truth available\n",
    "    \n",
    "    # Run the pipeline\n",
    "    active_learning_pipeline(\n",
    "        base_dir=base_dir,\n",
    "        initial_train_data=initial_train_data,\n",
    "        initial_train_labels=initial_train_labels,\n",
    "        unlabeled_data=unlabeled_data,\n",
    "        validation_labels=validation_labels,\n",
    "        total_iterations=10,           # Number of active learning iterations\n",
    "        samples_per_iteration=50,     # Number of uncertain samples to select per iteration\n",
    "        uncertainty_threshold=0.5,    # Threshold for high/low uncertainty classification\n",
    "        num_epochs=200,               # Number of training epochs per iteration\n",
    "        batch_size=16                 # Batch size for training\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b269afed-dee2-4bda-9b9a-c4f48f398ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, Dataset, Subset\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import jaccard_score\n",
    "# from collections import defaultdict\n",
    "# from scipy.stats import entropy\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Class Names\n",
    "# class_names = [\n",
    "#     \"Background\", \"Bareland\", \"Rangeland\", \"Developed Space\", \"Road\",\n",
    "#     \"Tree\", \"Water\", \"Agriculture Land\", \"Building\"\n",
    "# ]\n",
    "# num_classes = len(class_names)\n",
    "\n",
    "# # Dataset Class\n",
    "# class SegmentationDataset(Dataset):\n",
    "#     def __init__(self, image_dir, label_dir=None, transform=None):\n",
    "#         self.image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir)])\n",
    "#         self.label_paths = None if label_dir is None else sorted([os.path.join(label_dir, lbl) for lbl in os.listdir(label_dir)])\n",
    "#         self.transform = transform\n",
    "#         self.labeled = label_dir is not None\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = cv2.imread(self.image_paths[idx])\n",
    "#         image = cv2.resize(image, (512, 512))\n",
    "#         image_tensor = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "#         if self.labeled:\n",
    "#             label = cv2.imread(self.label_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "#             label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "#             label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "#             return image_tensor, label_tensor, self.image_paths[idx]\n",
    "#         else:\n",
    "#             return image_tensor, self.image_paths[idx]\n",
    "\n",
    "# # UNet Model\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, num_classes=9):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.contracting_11 = self.conv_block(3, 64)\n",
    "#         self.contracting_12 = nn.MaxPool2d(2, 2)\n",
    "#         self.contracting_21 = self.conv_block(64, 128)\n",
    "#         self.contracting_22 = nn.MaxPool2d(2, 2)\n",
    "#         self.contracting_31 = self.conv_block(128, 256)\n",
    "#         self.contracting_32 = nn.MaxPool2d(2, 2)\n",
    "#         self.contracting_41 = self.conv_block(256, 512)\n",
    "#         self.contracting_42 = nn.MaxPool2d(2, 2)\n",
    "#         self.middle = self.conv_block(512, 1024)\n",
    "#         self.expansive_11 = nn.ConvTranspose2d(1024, 512, 3, 2, 1, 1)\n",
    "#         self.expansive_12 = self.conv_block(1024, 512)\n",
    "#         self.expansive_21 = nn.ConvTranspose2d(512, 256, 3, 2, 1, 1)\n",
    "#         self.expansive_22 = self.conv_block(512, 256)\n",
    "#         self.expansive_31 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "#         self.expansive_32 = self.conv_block(256, 128)\n",
    "#         self.expansive_41 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n",
    "#         self.expansive_42 = self.conv_block(128, 64)\n",
    "#         self.output = nn.Conv2d(64, num_classes, 3, 1, 1)\n",
    "\n",
    "#     def conv_block(self, in_channels, out_channels):\n",
    "#         return nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(out_channels)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         c1 = self.contracting_11(x)\n",
    "#         p1 = self.contracting_12(c1)\n",
    "#         c2 = self.contracting_21(p1)\n",
    "#         p2 = self.contracting_22(c2)\n",
    "#         c3 = self.contracting_31(p2)\n",
    "#         p3 = self.contracting_32(c3)\n",
    "#         c4 = self.contracting_41(p3)\n",
    "#         p4 = self.contracting_42(c4)\n",
    "#         middle = self.middle(p4)\n",
    "#         u1 = self.expansive_11(middle)\n",
    "#         u1 = self.expansive_12(torch.cat((u1, c4), dim=1))\n",
    "#         u2 = self.expansive_21(u1)\n",
    "#         u2 = self.expansive_22(torch.cat((u2, c3), dim=1))\n",
    "#         u3 = self.expansive_31(u2)\n",
    "#         u3 = self.expansive_32(torch.cat((u3, c2), dim=1))\n",
    "#         u4 = self.expansive_41(u3)\n",
    "#         u4 = self.expansive_42(torch.cat((u4, c1), dim=1))\n",
    "#         output = self.output(u4)\n",
    "#         return output\n",
    "\n",
    "# # Compute Entropy for Uncertainty\n",
    "# def compute_entropy(probs):\n",
    "#     \"\"\"Compute pixel-wise entropy from probability map\"\"\"\n",
    "#     return -np.sum(probs * np.log(probs + 1e-10), axis=0)\n",
    "\n",
    "# # Class for Active Learning Sample Selection\n",
    "# class ActiveLearningSelector:\n",
    "#     def __init__(self, model, unlabeled_dataset, alpha=0.7, batch_size=10):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             model: The trained model\n",
    "#             unlabeled_dataset: Dataset of unlabeled samples\n",
    "#             alpha: Weight balance between uncertainty and diversity (higher alpha = more weight on uncertainty)\n",
    "#             batch_size: Number of samples to select in each active learning round\n",
    "#         \"\"\"\n",
    "#         self.model = model\n",
    "#         self.unlabeled_dataset = unlabeled_dataset\n",
    "#         self.alpha = alpha\n",
    "#         self.batch_size = batch_size\n",
    "#         self.device = next(model.parameters()).device\n",
    "        \n",
    "#     def get_class_distribution(self, labeled_indices):\n",
    "#         \"\"\"Calculate class distribution in current labeled dataset\"\"\"\n",
    "#         class_counts = np.zeros(num_classes)\n",
    "        \n",
    "#         # Create dataloader for the labeled subset\n",
    "#         labeled_subset = Subset(self.unlabeled_dataset, labeled_indices)\n",
    "#         loader = DataLoader(labeled_subset, batch_size=1)\n",
    "        \n",
    "#         for img, path in loader:\n",
    "#             img = img.to(self.device)\n",
    "#             with torch.no_grad():\n",
    "#                 output = self.model(img)\n",
    "#                 pred_mask = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "                \n",
    "#                 for cls in range(num_classes):\n",
    "#                     class_counts[cls] += (pred_mask == cls).sum()\n",
    "                    \n",
    "#         return class_counts / class_counts.sum()\n",
    "        \n",
    "#     def select_samples(self, labeled_indices=None):\n",
    "#         \"\"\"\n",
    "#         Select the next batch of samples for labeling\n",
    "        \n",
    "#         Args:\n",
    "#             labeled_indices: Indices of samples that are already labeled\n",
    "            \n",
    "#         Returns:\n",
    "#             List of indices to be labeled next\n",
    "#         \"\"\"\n",
    "#         unlabeled_loader = DataLoader(self.unlabeled_dataset, batch_size=1)\n",
    "#         all_scores = []\n",
    "#         all_indices = []\n",
    "        \n",
    "#         # Get class distribution in current labeled set if available\n",
    "#         if labeled_indices and len(labeled_indices) > 0:\n",
    "#             class_distribution = self.get_class_distribution(labeled_indices)\n",
    "#             # Convert to inverse weights (less represented classes get higher weights)\n",
    "#             class_weights = 1.0 / (class_distribution + 1e-5)\n",
    "#             # Normalize weights\n",
    "#             class_weights = class_weights / class_weights.sum()\n",
    "#         else:\n",
    "#             # If no labeled data yet, use uniform weights\n",
    "#             class_weights = np.ones(num_classes) / num_classes\n",
    "            \n",
    "#         print(\"Class weights for diversity:\", class_weights)\n",
    "        \n",
    "#         # Calculate scores for all unlabeled samples\n",
    "#         for i, (img, path) in enumerate(unlabeled_loader):\n",
    "#             if labeled_indices and i in labeled_indices:\n",
    "#                 continue\n",
    "                \n",
    "#             img = img.to(self.device)\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 output = self.model(img)\n",
    "#                 probs = F.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                \n",
    "#                 # Calculate uncertainty score (mean entropy)\n",
    "#                 entropy_map = compute_entropy(probs)\n",
    "#                 uncertainty_score = entropy_map.mean()\n",
    "                \n",
    "#                 # Calculate class distribution in this sample\n",
    "#                 pred_mask = np.argmax(probs, axis=0)\n",
    "#                 sample_class_counts = np.zeros(num_classes)\n",
    "#                 for cls in range(num_classes):\n",
    "#                     sample_class_counts[cls] = (pred_mask == cls).sum()\n",
    "                    \n",
    "#                 # Normalize to get class distribution\n",
    "#                 if sample_class_counts.sum() > 0:\n",
    "#                     sample_class_distribution = sample_class_counts / sample_class_counts.sum()\n",
    "#                 else:\n",
    "#                     sample_class_distribution = np.ones(num_classes) / num_classes\n",
    "                \n",
    "#                 # Calculate diversity score (weighted by class representation)\n",
    "#                 diversity_score = np.sum(sample_class_distribution * class_weights)\n",
    "                \n",
    "#                 # Combined score (alpha controls the balance)\n",
    "#                 combined_score = self.alpha * uncertainty_score + (1 - self.alpha) * diversity_score\n",
    "                \n",
    "#                 all_scores.append({\n",
    "#                     'index': i,\n",
    "#                     'path': path[0],\n",
    "#                     'uncertainty': uncertainty_score,\n",
    "#                     'diversity': diversity_score,\n",
    "#                     'combined_score': combined_score,\n",
    "#                     'class_distribution': sample_class_distribution\n",
    "#                 })\n",
    "#                 all_indices.append(i)\n",
    "        \n",
    "#         # Sort by combined score (higher is better)\n",
    "#         sorted_samples = sorted(all_scores, key=lambda x: x['combined_score'], reverse=True)\n",
    "        \n",
    "#         # Class-balanced sampling\n",
    "#         # First, select a larger candidate pool based on combined score\n",
    "#         candidate_pool = sorted_samples[:min(len(sorted_samples), self.batch_size * 3)]\n",
    "        \n",
    "#         # Implement class-balanced selection from candidate pool\n",
    "#         selected_indices = []\n",
    "#         target_class_counts = np.zeros(num_classes)\n",
    "        \n",
    "#         # Fill the batch with balanced class representation\n",
    "#         while len(selected_indices) < self.batch_size and candidate_pool:\n",
    "#             best_score = -float('inf')\n",
    "#             best_idx = -1\n",
    "#             best_candidate_idx = -1\n",
    "            \n",
    "#             for i, candidate in enumerate(candidate_pool):\n",
    "#                 if candidate['index'] in selected_indices:\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Calculate how well this sample balances the class distribution\n",
    "#                 temp_counts = target_class_counts.copy()\n",
    "#                 for cls in range(num_classes):\n",
    "#                     temp_counts[cls] += candidate['class_distribution'][cls]\n",
    "                \n",
    "#                 # Entropy of class distribution (higher is more balanced)\n",
    "#                 balance_score = entropy(temp_counts + 1e-10)\n",
    "                \n",
    "#                 # Final score combines original score with balance\n",
    "#                 final_score = 0.7 * candidate['combined_score'] + 0.3 * balance_score\n",
    "                \n",
    "#                 if final_score > best_score:\n",
    "#                     best_score = final_score\n",
    "#                     best_idx = candidate['index']\n",
    "#                     best_candidate_idx = i\n",
    "            \n",
    "#             if best_idx != -1:\n",
    "#                 selected_indices.append(best_idx)\n",
    "#                 # Update target class counts\n",
    "#                 for cls in range(num_classes):\n",
    "#                     target_class_counts[cls] += candidate_pool[best_candidate_idx]['class_distribution'][cls]\n",
    "#                 # Remove from candidate pool\n",
    "#                 candidate_pool.pop(best_candidate_idx)\n",
    "#             else:\n",
    "#                 break\n",
    "                \n",
    "#         # Print summary of selected samples\n",
    "#         print(f\"Selected {len(selected_indices)} samples for labeling\")\n",
    "#         return selected_indices\n",
    "\n",
    "# # Function to train with Active Learning\n",
    "# def train_active_learning(\n",
    "#     initial_model_path,\n",
    "#     unlabeled_img_dir,\n",
    "#     labeled_img_dir,\n",
    "#     labeled_label_dir,\n",
    "#     output_dir=\"output\",\n",
    "#     initial_labeled_samples=50,\n",
    "#     active_learning_rounds=5,\n",
    "#     samples_per_round=10,\n",
    "#     epochs_per_round=5,\n",
    "#     alpha=0.7\n",
    "# ):\n",
    "#     # Create output directories\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     os.makedirs(os.path.join(output_dir, \"models\"), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(output_dir, \"selected_samples\"), exist_ok=True)\n",
    "    \n",
    "#     # Load initial model\n",
    "#     model = UNet(num_classes=num_classes).to(device)\n",
    "#     if os.path.exists(initial_model_path):\n",
    "#         checkpoint = torch.load(initial_model_path, map_location=device)\n",
    "#         # Handle both DataParallel and non-DataParallel models\n",
    "#         if \"module.\" in list(checkpoint.keys())[0]:\n",
    "#             model = nn.DataParallel(model)\n",
    "#         model.load_state_dict(checkpoint)\n",
    "    \n",
    "#     # Create datasets\n",
    "#     unlabeled_dataset = SegmentationDataset(unlabeled_img_dir)\n",
    "#     labeled_dataset = SegmentationDataset(labeled_img_dir, labeled_label_dir)\n",
    "    \n",
    "#     # Initial training if there's labeled data\n",
    "#     if len(labeled_dataset) > 0:\n",
    "#         print(f\"Initial training with {len(labeled_dataset)} labeled samples\")\n",
    "#         train_model(model, labeled_dataset, epochs=epochs_per_round)\n",
    "#         torch.save(model.state_dict(), os.path.join(output_dir, \"models\", \"initial_model.pth\"))\n",
    "    \n",
    "#     # Initialize active learning selector\n",
    "#     selector = ActiveLearningSelector(model, unlabeled_dataset, alpha=alpha, batch_size=samples_per_round)\n",
    "    \n",
    "#     # Track labeled indices\n",
    "#     labeled_indices = []\n",
    "#     if initial_labeled_samples > 0:\n",
    "#         # Random selection for initial labeled set\n",
    "#         labeled_indices = np.random.choice(\n",
    "#             len(unlabeled_dataset), \n",
    "#             size=min(initial_labeled_samples, len(unlabeled_dataset)),\n",
    "#             replace=False\n",
    "#         ).tolist()\n",
    "        \n",
    "#     # Metrics tracking\n",
    "#     round_metrics = []\n",
    "    \n",
    "#     # Active learning loop\n",
    "#     for round_idx in range(active_learning_rounds):\n",
    "#         print(f\"\\n--- Active Learning Round {round_idx+1}/{active_learning_rounds} ---\")\n",
    "        \n",
    "#         # Select samples\n",
    "#         new_indices = selector.select_samples(labeled_indices)\n",
    "#         labeled_indices.extend(new_indices)\n",
    "        \n",
    "#         # Save selected samples info\n",
    "#         round_info = {\n",
    "#             'round': round_idx + 1,\n",
    "#             'selected_indices': new_indices,\n",
    "#             'selected_paths': [unlabeled_dataset.image_paths[i] for i in new_indices]\n",
    "#         }\n",
    "        \n",
    "#         # Here you would typically:\n",
    "#         # 1. Get these images labeled (manual annotation process)\n",
    "#         # 2. Add them to your labeled dataset\n",
    "#         # For simulation, we'll just print the paths\n",
    "        \n",
    "#         print(f\"Selected {len(new_indices)} new samples for labeling:\")\n",
    "#         for idx in new_indices:\n",
    "#             print(f\"  - {unlabeled_dataset.image_paths[idx]}\")\n",
    "        \n",
    "#         # In a real scenario, after getting labels:\n",
    "#         # 1. Move these samples from unlabeled to labeled dataset\n",
    "#         # 2. Retrain model with updated labeled dataset\n",
    "        \n",
    "#         print(f\"Retraining model with {len(labeled_indices)} total labeled samples\")\n",
    "        \n",
    "#         # Simulate: In practice, you would retrain with actual labeled data\n",
    "#         # For now, we'll just update metrics and save the round info\n",
    "        \n",
    "#         # Evaluate on validation set (if available)\n",
    "#         # val_miou = evaluate_model(model, val_dataset)\n",
    "#         val_miou = 0.0  # Placeholder\n",
    "        \n",
    "#         round_metrics.append({\n",
    "#             'round': round_idx + 1,\n",
    "#             'num_labeled_samples': len(labeled_indices),\n",
    "#             'val_miou': val_miou\n",
    "#         })\n",
    "        \n",
    "#         # Save round information\n",
    "#         pd.DataFrame([round_info]).to_csv(\n",
    "#             os.path.join(output_dir, \"selected_samples\", f\"round_{round_idx+1}.csv\"),\n",
    "#             index=False\n",
    "#         )\n",
    "        \n",
    "#         # Save model for this round\n",
    "#         torch.save(model.state_dict(), \n",
    "#                   os.path.join(output_dir, \"models\", f\"model_round_{round_idx+1}.pth\"))\n",
    "    \n",
    "#     # Save final metrics\n",
    "#     pd.DataFrame(round_metrics).to_csv(\n",
    "#         os.path.join(output_dir, \"active_learning_metrics.csv\"),\n",
    "#         index=False\n",
    "#     )\n",
    "    \n",
    "#     # Plot learning curve\n",
    "#     if round_metrics:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         rounds = [m['round'] for m in round_metrics]\n",
    "#         mious = [m['val_miou'] for m in round_metrics]\n",
    "#         plt.plot(rounds, mious, 'o-', linewidth=2)\n",
    "#         plt.title('Active Learning Progress', fontsize=16)\n",
    "#         plt.xlabel('Round', fontsize=14)\n",
    "#         plt.ylabel('Validation mIoU', fontsize=14)\n",
    "#         plt.grid(True)\n",
    "#         plt.savefig(os.path.join(output_dir, \"learning_curve.png\"), dpi=300)\n",
    "#         plt.close()\n",
    "    \n",
    "#     print(\"Active Learning completed successfully!\")\n",
    "#     return model, labeled_indices\n",
    "\n",
    "# # Function to train model for a few epochs\n",
    "# def train_model(model, dataset, epochs=5, batch_size=4):\n",
    "#     \"\"\"Train model for a few epochs on the given dataset\"\"\"\n",
    "#     train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         running_loss = 0.0\n",
    "#         for i, (imgs, labels, _) in enumerate(train_loader):\n",
    "#             imgs = imgs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(imgs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item()\n",
    "            \n",
    "#             if (i+1) % 10 == 0:\n",
    "#                 print(f\"Epoch {epoch+1}/{epochs}, Batch {i+1}, Loss: {running_loss/10:.4f}\")\n",
    "#                 running_loss = 0.0\n",
    "                \n",
    "#     return model\n",
    "\n",
    "# # Function to evaluate model performance\n",
    "# def evaluate_model(model, dataset):\n",
    "#     \"\"\"Evaluate model on dataset and return mIoU\"\"\"\n",
    "#     val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "#     model.eval()\n",
    "    \n",
    "#     overall_iou_per_class = np.zeros(num_classes)\n",
    "#     total_images = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for img, lbl, _ in val_loader:\n",
    "#             img = img.to(device)\n",
    "#             output = model(img)\n",
    "#             probs = F.softmax(output, dim=1).cpu().numpy()\n",
    "#             pred_mask = np.argmax(probs, axis=1)[0]\n",
    "#             lbl_np = lbl.cpu().numpy()[0]\n",
    "            \n",
    "#             # Compute IoU\n",
    "#             miou, classwise_iou = compute_miou(pred_mask, lbl_np)\n",
    "#             overall_iou_per_class += np.nan_to_num(classwise_iou)\n",
    "#             total_images += 1\n",
    "    \n",
    "#     avg_miou = np.nanmean(overall_iou_per_class) / total_images\n",
    "#     return avg_miou\n",
    "\n",
    "# # Compute mIoU\n",
    "# def compute_miou(preds, targets):\n",
    "#     iou_per_class = np.zeros(num_classes)\n",
    "#     preds = preds.flatten()\n",
    "#     targets = targets.flatten()\n",
    "#     for cls in range(num_classes):\n",
    "#         if (targets == cls).sum() == 0:\n",
    "#             iou_per_class[cls] = np.nan\n",
    "#             continue\n",
    "#         iou_per_class[cls] = jaccard_score(targets == cls, preds == cls)\n",
    "#     return np.nanmean(iou_per_class), iou_per_class\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     initial_model_path = \"base_unet_model.pth\"\n",
    "#     unlabeled_img_dir = \"unlabeled/images\"\n",
    "#     labeled_img_dir = \"labeled/images\"\n",
    "#     labeled_label_dir = \"labeled/labels\"\n",
    "    \n",
    "#     # Start active learning process\n",
    "#     train_active_learning(\n",
    "#         initial_model_path=initial_model_path,\n",
    "#         unlabeled_img_dir=unlabeled_img_dir,\n",
    "#         labeled_img_dir=labeled_img_dir,\n",
    "#         labeled_label_dir=labeled_label_dir,\n",
    "#         initial_labeled_samples=50,  # Start with 50 random samples\n",
    "#         active_learning_rounds=5,    # Do 5 rounds of active learning\n",
    "#         samples_per_round=10,        # Select 10 samples per round\n",
    "#         epochs_per_round=5,          # Train for 5 epochs in each round\n",
    "#         alpha=0.7                    # Balance between uncertainty (0.7) and diversity (0.3)\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
